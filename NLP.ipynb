{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b8f1d4",
   "metadata": {},
   "source": [
    "\n",
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386c34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr # for online speech recognition\n",
    "\n",
    "# for recording audio and saving\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "\n",
    "# for data pre-processing\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "import random as rd\n",
    "\n",
    "# for 3d scene genration\n",
    "from direct.showbase.ShowBase import ShowBase\n",
    "from panda3d.core import *\n",
    "import time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413ece2",
   "metadata": {},
   "source": [
    "# Importing Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccee7d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigPage , 1 declarations."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = open(\"noun.text\", 'r').read().splitlines()\n",
    "pos = open(\"pos.txt\", 'r').read().splitlines()\n",
    "comman_words = pd.read_csv('Comman-Words.csv')\n",
    "chars_dict = pd.read_csv('Char-dict.csv')\n",
    "replace  = open('replace.txt', 'r').read().splitlines()\n",
    "meta_data = pd.read_csv('meta_data.csv') # data about the 3d models\n",
    "\n",
    "loadPrcFileData(\"\", \"load-file-type p3assimp\") # for panda3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7768091",
   "metadata": {},
   "source": [
    "# Speech to Urdu Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordAudio():\n",
    "    # Sampling frequency\n",
    "    freq = 48000\n",
    "\n",
    "    # Recording duration\n",
    "    duration = 7\n",
    "\n",
    "    # Start recorder with the given values \n",
    "    # of duration and sample frequency\n",
    "    recording = sd.rec(int(duration * freq), \n",
    "                       samplerate=freq, channels=2)\n",
    "\n",
    "    # Record audio for the given number of seconds\n",
    "    sd.wait()\n",
    "\n",
    "    # This will convert the NumPy array to an audio\n",
    "    # file with the given sampling frequency\n",
    "    write(\"recording0.wav\", freq, recording)\n",
    "\n",
    "    # Convert the NumPy array to audio file\n",
    "    wv.write(\"recording1.wav\", recording, freq, sampwidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80573eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Audio2Text():\n",
    "    print(\"You have 7 sec to speak, start with \\\"Hey Google\\\"\")\n",
    "    recordAudio()\n",
    "    \n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    audio = sr.AudioFile(\"recording1.wav\")\n",
    "    with audio as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.record(source)\n",
    "\n",
    "\n",
    "    # GOOGLE speech to urdu conversion\n",
    "    try:\n",
    "        data = recognizer.recognize_google(audio, language='ur-PK')\n",
    "        return data\n",
    "    except:\n",
    "        print('Voice not Recognized')\n",
    "    return data\n",
    "\n",
    "text = Audio2Text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3de6d0",
   "metadata": {},
   "source": [
    "# Transliteration: Urdu To Roman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b919844",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             new_roman\u001b[38;5;241m.\u001b[39mappend(urdu_word)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(new_roman)\n\u001b[0;32m---> 51\u001b[0m sentence \u001b[38;5;241m=\u001b[39m urdu2roman(\u001b[43mtext\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "def convert_to_roman(word):\n",
    "    '''\n",
    "        1. Got a word, break into characters\n",
    "        2. Iterate over characters and map if it is valid character else append as it is\n",
    "        3. Return a word by joining all mapped characters\n",
    "    '''\n",
    "    \n",
    "    chars = re.findall(r'[\\u0600-\\u06ff]',word)\n",
    "    roman_chars = []\n",
    "    \n",
    "    for char in chars:\n",
    "        ch = (chars_dict.loc[chars_dict['Urdu'] == char].values)\n",
    "        try:\n",
    "            roman_chars.append(ch[0][1])\n",
    "        except:\n",
    "            roman_chars.append(char)\n",
    "            \n",
    "    return ''.join(roman_chars)\n",
    "\n",
    "\n",
    "def urdu2roman(sentence):\n",
    "    '''\n",
    "        1. Got a sentence, break it into words\n",
    "        2. Iterate over words, try to map word using comman word, else map by character if word is urdu,\n",
    "           finally append as it is\n",
    "        3. Return a sentence by joining all mapped words\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    new_roman = []\n",
    "    urdu_words = sentence.split(' ')\n",
    "    \n",
    "    for urdu_word in urdu_words:\n",
    "        flag=True #flag indicated that word conversion is remaining\n",
    "        roman_word = (comman_words.loc[comman_words['Urdu'] == urdu_word].values)\n",
    "        if len(roman_word)>0:\n",
    "            new_roman.append(roman_word[0][0])\n",
    "            flag=False\n",
    "        \n",
    "        if flag:\n",
    "            roman_word = convert_to_roman(urdu_word)\n",
    "            if roman_word!='':\n",
    "                new_roman.append(roman_word)\n",
    "                flag=False\n",
    "        \n",
    "        if flag:\n",
    "            new_roman.append(urdu_word)\n",
    "    \n",
    "    return ' '.join(new_roman)\n",
    "\n",
    "sentence = urdu2roman(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221619d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c5ba3",
   "metadata": {},
   "source": [
    "### Converting to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300ca295",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[43msentence\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = sentence.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd9dc5",
   "metadata": {},
   "source": [
    "### Replacing Similar Words with one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04562a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         it\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(new_sentence)\n\u001b[0;32m---> 35\u001b[0m sentence \u001b[38;5;241m=\u001b[39m replaceWords(\u001b[43msentence\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "def replaceWords(sentence):\n",
    "    global replace\n",
    "    \n",
    "    new_sentence = []\n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    it = 0\n",
    "    while it < len(words):\n",
    "        word = words[it]\n",
    "        appendFlag = True\n",
    "    \n",
    "        if word=='main' and words[it+1]=='is':\n",
    "            new_sentence.append('maiz')\n",
    "            it += 2\n",
    "            word = words[it]\n",
    "        \n",
    "        for replaceW in replace:\n",
    "            correctWord, wrongWords = replaceW.split(':')\n",
    "            for wrongW in wrongWords.split(','):\n",
    "                if word==wrongW:\n",
    "                    new_sentence.append(correctWord)\n",
    "                    appendFlag = False\n",
    "                    break\n",
    "            if not appendFlag:\n",
    "                break\n",
    "                \n",
    "        if appendFlag:\n",
    "            new_sentence.append(word)\n",
    "        it+=1\n",
    "        \n",
    "    return \" \".join(new_sentence)\n",
    "        \n",
    "    \n",
    "    \n",
    "sentence = replaceWords(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbb1b8",
   "metadata": {},
   "source": [
    "### Replacing Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6b0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacePronouns(sentence):\n",
    "    pronouns = ['uska', 'uski', 'uske', 'iske']\n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    noun = \"\"\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in entities:\n",
    "            noun = words[i]\n",
    "        elif words[i] in pronouns:\n",
    "            words[i] = noun\n",
    "    \n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf7163",
   "metadata": {},
   "source": [
    "### Spliting Multiple Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5908b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentence(data):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    words = data.split(\" \")\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        sentence.append(words[i])\n",
    "        if words[i] == \"hai\" and (i==len(words)-1 or words[i+1]==\"aur\"):\n",
    "            sentences.append(\" \".join(sentence))\n",
    "            sentence.clear()\n",
    "    \n",
    "    if len(sentence)!=0:\n",
    "        sentences.append(\" \".join(sentence))\n",
    "\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52157d16",
   "metadata": {},
   "source": [
    "### Get Entities with Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c700c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntitiesRelation(sentence):\n",
    "    objects = []\n",
    "    positions = []\n",
    "    \n",
    "    for word in sentence.split(' '):\n",
    "        if word in entities:\n",
    "            objects.append(word)\n",
    "        if word in pos:\n",
    "            positions.append(word)\n",
    "            \n",
    "    return objects, positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566948cb",
   "metadata": {},
   "source": [
    "### Rephrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c86de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipSentence(sentence):\n",
    "    sentences = sentence.split(' hai ')\n",
    "    if len(sentences)==1:\n",
    "        return sentence\n",
    "    else:\n",
    "        return sentences[1]+\" \"+sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2db95",
   "metadata": {},
   "source": [
    "# Making Graph from Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d88079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGraph(data):\n",
    "    graph = dict()\n",
    "    data = replacePronouns(data)\n",
    "    sentences = splitSentence(data)\n",
    "    \n",
    "#     print(sentences)\n",
    "    for sentence in sentences:\n",
    "        if sentence.split(' ')[-1] != 'hai':\n",
    "            sentence = flipSentence(sentence)\n",
    "        print(sentence)\n",
    "        objects, positions = getEntitiesRelation(sentence)\n",
    "        node1 = node2 = None\n",
    "        \n",
    "        \n",
    "        for j in range(len(positions)):\n",
    "            position = positions[j]\n",
    "            if position == \"darmian\":\n",
    "                node1 = objects.pop(0)+\" \"+objects.pop(0)\n",
    "            elif position != \"darmian\" and node2==None:\n",
    "                node1 = objects.pop(0)\n",
    "            node2 = objects.pop(0)\n",
    "            \n",
    "            if j == len(positions)-1:\n",
    "                for obj in objects:\n",
    "                    if node1 == node2:\n",
    "                        node2 =  obj\n",
    "                    else:\n",
    "                        node2 += \" \"+obj\n",
    "            \n",
    "            if node1 not in graph.keys():\n",
    "                graph[node1] = [(node2, position)]\n",
    "            else:\n",
    "                graph[node1].append((node2, position))\n",
    "            node1 = node2\n",
    "                \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688153e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "105f8734",
   "metadata": {},
   "source": [
    "# Get 3d Models' relative Positions from Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ea6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setPositions(_3dMaps, parent, Node, pos):\n",
    "    global meta_data\n",
    "    \n",
    "    node = Node.split(' ')[0]\n",
    "\n",
    "\n",
    "    if pos==\"darmian\":\n",
    "        P = _3dMaps[-2]\n",
    "        parent_data = (meta_data[meta_data['Model']==P[0]].values)[0]\n",
    "        child_data = (meta_data[meta_data['Model']==node].values)[0]\n",
    "        new_value = (node, child_data[1], (P[2][0] + parent_data[2] + child_data[2] + 0.1 , P[2][1], P[2][2]))\n",
    "        _3dMaps.append(new_value)\n",
    "\n",
    "\n",
    "\n",
    "    if pos == 'sath':\n",
    "        pos = rd.sample(['aage', 'peeche'])\n",
    "    \n",
    "    \n",
    "    P = None\n",
    "    for C in _3dMaps:\n",
    "        if C[0] == parent:\n",
    "            P = C\n",
    "            break\n",
    "    parent_data = (meta_data[meta_data['Model']==parent].values)[0]\n",
    "    child_data = (meta_data[meta_data['Model']==node].values)[0]\n",
    "\n",
    "    if pos == 'dai':\n",
    "        new_value = (node, child_data[1], (P[2][0] + parent_data[2] + child_data[2] + 0.1 , P[2][1], P[2][2]))\n",
    "    elif pos == 'bai':\n",
    "        new_value = (node, child_data[1], (P[2][0] - parent_data[2] - child_data[2] - 0.1 , P[2][1], P[2][2]))\n",
    "    elif pos == 'aage':\n",
    "        new_value = (node, child_data[1], (P[2][0] , P[2][1], P[2][2] + parent_data[4] + child_data[4]+0.1))\n",
    "    elif pos == 'peeche':\n",
    "        new_value = (node, child_data[1], (P[2][0] , P[2][1], P[2][2] - parent_data[4] - child_data[4] - 0.1))\n",
    "    elif pos == 'ooper':\n",
    "        new_value = (node, child_data[1], (P[2][0] , P[2][1]+parent_data[3]+child_data[3], P[2][2]))\n",
    "    elif pos == 'neeche':\n",
    "        new_value = (node, child_data[1], (P[2][0] , P[2][1]-child_data[3], P[2][2]))\n",
    "    elif pos=='mein':\n",
    "        new_value = (node, child_data[1], (P[2][0] , P[2][1]+0.02, P[2][2]))\n",
    "    _3dMaps.append(new_value)\n",
    "\n",
    "    print(_3dMaps)\n",
    "    if len(Node.split(' ')) > 1:\n",
    "        setPositions(_3dMaps, Node.split(' ')[0], Node.split(' ')[1:], pos)\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "def DFS(graph, node, visited, _3dMaps, parent=None, pos=None):\n",
    "    visited.add(node)\n",
    "    if pos == None and parent==None:\n",
    "        global data\n",
    "        if len(node.split(' '))==0:\n",
    "            data = meta_data[meta_data['Model']==node].values[0]\n",
    "            _3dMaps.append((node, data[1], (0, 0, 0)))\n",
    "        else:\n",
    "            i = 0\n",
    "            for N in node.split(' '):\n",
    "                data = meta_data[meta_data['Model']==N].values[0]\n",
    "                if i==0:\n",
    "                    _3dMaps.append((N, data[1], (0, 0, 0)))\n",
    "                else:\n",
    "                    _3dMaps.append((N, data[1], (4, 0, 0)))\n",
    "                i+=1\n",
    "\n",
    "    else:\n",
    "        setPositions(_3dMaps, parent, node, pos)\n",
    "    \n",
    "    try:\n",
    "        for n, p in graph[node]:\n",
    "            if n not in visited:\n",
    "                DFS(graph, n, visited, _3dMaps, node, p)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def mapping(graph):\n",
    "    visited = set()\n",
    "    start = list(graph.keys())[0]\n",
    "    _3dMaps = []\n",
    "    \n",
    "    DFS(graph, start, visited, _3dMaps)\n",
    "    \n",
    "    return _3dMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba91f7b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m graph \u001b[38;5;241m=\u001b[39m makeGraph(\u001b[43msentence\u001b[49m)\n\u001b[1;32m      2\u001b[0m maps \u001b[38;5;241m=\u001b[39m mapping(graph)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": [
    "graph = makeGraph(sentence)\n",
    "maps = mapping(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037a9ff",
   "metadata": {},
   "source": [
    "# 3D Scene Genration(works better in PY file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e32f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Known pipe types:\n",
      "  glxGraphicsPipe\n",
      "(1 aux display modules not yet loaded.)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyApp(ShowBase):\n",
    "\n",
    "\n",
    "    def __init__(self, models):\n",
    "\n",
    "        ShowBase.__init__(self)\n",
    "        data = []\n",
    "        for model in models:\n",
    "            path = \"Models/\"+model[0]+\".obj\"\n",
    "            M = self.loader.loadModel(path)\n",
    "            M.reparentTo(self.render)\n",
    "            M.setScale(model[1], model[1], model[1])\n",
    "            M.setPos(model[2][0], model[2][1], model[2][2])\n",
    "            data.append(M)\n",
    "        \n",
    "\n",
    "app = MyApp(maps)\n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e10a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5df9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
